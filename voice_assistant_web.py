import gradio as gr
import sounddevice as sd
import numpy as np
import whisper
import cohere
from gtts import gTTS
from playsound import playsound
import tempfile
import os

class ArabicVoiceAssistant:
    def __init__(self):
        self.audio_model = whisper.load_model("small")
        self.co = cohere.Client("")
        self.response_path = None

    def record_and_process(self, duration):
        try:
            print("\n Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„...")
            audio = sd.rec(int(duration * 16000), samplerate=16000, channels=1, dtype='float32')
            sd.wait()
            audio = np.squeeze(audio)

            print(" ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ...")
            result = self.audio_model.transcribe(audio, language='ar')
            user_text = result["text"].strip()

            if "ØªÙˆÙ‚Ù" in user_text:
                reply = "Ù…Ø¹ Ø§Ù„Ø³Ù„Ø§Ù…Ø©!"
            else:
                print("ğŸ¤– ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯...")
                reply = self.co.chat(model="command-r7b-arabic-02-2025", message=user_text).text.strip()

            print(" ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø±Ø¯ Ø¥Ù„Ù‰ ØµÙˆØª...")
            tts = gTTS(text=reply, lang='ar')
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as fp:
                tts.save(fp.name)
                self.response_path = fp.name

            return user_text, reply, self.response_path

        except Exception as e:
            return f" Ø®Ø·Ø£: {e}", "", None

    def clear_audio(self):
        if self.response_path and os.path.exists(self.response_path):
            os.remove(self.response_path)
        self.response_path = None
        return "", "", None

assistant = ArabicVoiceAssistant()

with gr.Blocks(theme=gr.themes.Monochrome()) as app:
    gr.Markdown("## ğŸ™ï¸ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠ")
    gr.Markdown("Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø§Ù„Ø²Ø± Ù„ØªØ³Ø¬ÙŠÙ„ ØµÙˆØªÙƒØŒ ÙˆØ³ÙŠÙÙ‡Ù…Ùƒ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ ÙˆÙŠØ±Ø¯ Ø¹Ù„ÙŠÙƒ Ø¨ØµÙˆØª.")

    duration = gr.Slider(1, 10, value=5, step=0.5, label="Ù…Ø¯Ø© Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Ø¨Ø§Ù„Ø«ÙˆØ§Ù†ÙŠ)")
    start_btn = gr.Button("Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ³Ø¬ÙŠÙ„")
    clear_btn = gr.Button("Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ÙˆÙ…Ø³Ø­ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")

    user_out = gr.Textbox(label="ğŸ§‘ Ù…Ø§ Ù‚Ù„ØªÙ‡")
    bot_out = gr.Textbox(label="ğŸ¤– Ø±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯")
    audio_out = gr.Audio(label="ğŸ”Š ØµÙˆØª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯", type="filepath", autoplay=True)

    start_btn.click(fn=assistant.record_and_process, inputs=duration, outputs=[user_out, bot_out, audio_out])
    clear_btn.click(fn=assistant.clear_audio, outputs=[user_out, bot_out, audio_out])

app.launch()
